# -*- coding: utf-8 -*-
"""Sentiment_Model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1uMwxR2-441h2g_AWv1aPlaq7obHxINGi

#**Sentiment Analysis Model on E-Commerce Website**

### Install necessary packages
"""


"""### Imports"""

import re
import nltk
from nltk.corpus import stopwords
from nltk.stem import PorterStemmer
from nltk.tokenize import word_tokenize
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.pipeline import Pipeline
from sklearn.metrics import accuracy_score, precision_score, recall_score
import joblib
import streamlit as st

"""### Download NLTK resources"""

nltk.download('punkt')
nltk.download('stopwords')

"""### Define preprocessing function"""

def preprocess_text(text):
    text = text.lower()
    text = re.sub(r'\W', ' ', text)
    words = word_tokenize(text)
    words = [word for word in words if word not in stopwords.words("english")]
    words = [PorterStemmer().stem(word) for word in words]
    return " ".join(words)

"""### Load and preprocess training data"""

with open('/Users/maanavaryan/Documents/Project/sentiment_analysis_project/data/train.ft.txt', 'r') as train_file:
    train_data = train_file.readlines()

train_comments = [re.sub(r'^__label__[0-9]+ ', '', line).strip() for line in train_data]
train_labels = [re.findall(r'^__label__([0-9]+)', line)[0] for line in train_data]

"""### Train the model"""

train_pipeline = Pipeline([
    ('tfidf', TfidfVectorizer()),
    ('model', LogisticRegression(max_iter=100))
])
train_pipeline.fit(train_comments, train_labels)

"""### Save the trained model"""

model_filename = 'sentiment_model.pkl'
joblib.dump(train_pipeline, model_filename)

"""### Load and preprocess testing data"""

with open('/Users/maanavaryan/Documents/Project/sentiment_analysis_project/data/test.ft.txt', 'r') as test_file:
    test_data = test_file.readlines()

test_comments = [re.sub(r'^__label__[0-9]+ ', '', line).strip() for line in test_data]
test_labels = [re.findall(r'^__label__([0-9]+)', line)[0] for line in test_data]

"""### Predict on testing data"""

test_predictions = train_pipeline.predict(test_comments)

"""### Calculate evaluation metrics"""

accuracy = accuracy_score(test_labels, test_predictions)
precision = precision_score(test_labels, test_predictions, average='weighted')
recall = recall_score(test_labels, test_predictions, average='weighted')

"""## Streamlit app"""

st.title("E-commerce Sentiment Analysis")
comment = st.text_area("Enter your comment:")
if st.button("Analyze"):
    preprocessed_comment = preprocess_text(comment)
    sentiment = train_pipeline.predict([preprocessed_comment])[0]
    st.write("Predicted Sentiment:", sentiment)

"""### Display evaluation metrics"""

st.subheader("Model Evaluation Metrics")
st.write("Accuracy:", accuracy)
st.write("Precision:", precision)
st.write("Recall:", recall)